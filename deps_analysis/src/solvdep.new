#!/usr/bin/python

# vim: sw=4 et

import sys
import os
import glob
import solv
import re
import tempfile
import time
import subprocess
import rpm
from stat import *
import argparse 
import logging
import xml.etree.ElementTree as ET

logging.basicConfig()
logger=logging.getLogger()
logger.setLevel(logging.DEBUG)

CACHEDIR="./cache"

class pattern(dict):
    def __init__(self, name):
        self.name=name
        self.packages=set()
        self.dependencies=[]

    def add(self,pkgname):
        self.packages.add(pkgname)

    def solve(self):
        result={
            'all': set(),
            'depth': []
        }
        lookup_dependencies( lookup_packages(self.packages), result )
        self.depends=sorted(result['all'])
        self.depends_per_depth=sorted(result['depth'])


class repo_generic(dict):
    def __init__(self, name, type, attribs = {}):
        for k in attribs:
            self[k] = attribs[k]
        self.name = name
        self.type = type
        self.patterns={}

    def load(self, pool):
        self.handle = pool.add_repo(self.name)
        self.handle.appdata = self
        self.handle.priority = 99 - self['priority']
        return False

    def load_ext(self, repodata):
        return False

    def download(self, file, uncompress=False, chksum=None, markincomplete=False):
        url = None
        if 'baseurl' not in self:
            logger.error("Invalid baseurl")
            sys.exit(1)

        if not url:
            if 'baseurl' not in self:
                logger.error("%s: no baseurl" % self.name)
                return None
            url = re.sub(r'/$', '', self['baseurl']) + '/' + file

        if chksum is not None:
            logger.info("Looking for %s in cache %s" % (chksum,CACHEDIR))

        f = tempfile.TemporaryFile()
        logger.info("downloading %s to %s" % (url,f))
        st = subprocess.call(['curl', '-f', '-s', '-L', url], stdout=f.fileno())
        if os.lseek(f.fileno(), 0, os.SEEK_CUR) == 0 and (st == 0 or not chksum):
            return None
        os.lseek(f.fileno(), 0, os.SEEK_SET)
        if st:
            logger.error("%s: download error %d" % (file, st))
            if markincomplete:
                self['incomplete'] = True
            return None
        if chksum:
            fchksum = solv.Chksum(chksum.type)
            if not fchksum:
                logger.error("%s: unknown checksum type" % file)
                if markincomplete:
                    self['incomplete'] = True
                return None
            fchksum.add_fd(f.fileno())
            if fchksum != chksum:
                logger.error("%s: checksum mismatch" % file)
                if markincomplete:
                    self['incomplete'] = True
                return None
        if uncompress:
            return solv.xfopen_fd(file, f.fileno())
        return solv.xfopen_fd(None, f.fileno())
                
    def updateaddedprovides(self, addedprovides):
        if 'incomplete' in self:
            return 
        if not hasattr(self, 'handle'):
            return 
        if self.handle.isempty():
            return
        # make sure there's just one real repodata with extensions
        repodata = self.handle.first_repodata()
        if not repodata:
            return
        oldaddedprovides = repodata.lookup_idarray(solv.SOLVID_META, solv.REPOSITORY_ADDEDFILEPROVIDES)
        if not set(addedprovides) <= set(oldaddedprovides):
            for id in addedprovides:
                repodata.add_idarray(solv.SOLVID_META, solv.REPOSITORY_ADDEDFILEPROVIDES, id)
            repodata.internalize()


class repo_repomd(repo_generic):
    def load(self, pool):
        if super(repo_repomd, self).load(pool):
            return True
        logger.info("repo '%s'" % self.name)
        f = self.download("repodata/repomd.xml")
        if not f:
            logger.info("no repomd.xml file, skipped")
            self.handle.free(True)
            del self.handle
            return False
        
        self.handle.add_repomdxml(f, 0)
        (filename, filechksum) = self.find('primary')
        if filename:
            f = self.download(filename, uncompress=True, chksum=filechksum, markincomplete=True)
            if f:
                logger.info("downloaded primary")
                self.handle.add_rpmmd(f, None, 0)
            if 'incomplete' in self:
                return False # hopeless, need good primary
        (filename, filechksum) = self.find('updateinfo')
        if filename:
            f = self.download(filename, uncompress=True, chksum=filechksum, markincomplete=True)
            if f:
                self.handle.add_updateinfoxml(f, 0)
        self.add_exts()
        # must be called after writing the repo
        self.handle.create_stubs()

        # load patterns
        self.load_patterns()

        return True

    def find(self, what):
        di = self.handle.Dataiterator(solv.SOLVID_META, solv.REPOSITORY_REPOMD_TYPE, what, solv.Dataiterator.SEARCH_STRING)
        di.prepend_keyname(solv.REPOSITORY_REPOMD)
        for d in di:
            dp = d.parentpos()
            filename = dp.lookup_str(solv.REPOSITORY_REPOMD_LOCATION)
            logger.debug("Find: %s" % filename)
            chksum = dp.lookup_checksum(solv.REPOSITORY_REPOMD_CHECKSUM)
            if filename and not chksum:
                logger.error("no %s file checksum!" % filename)
                filename = None
                chksum = None
            if filename:
                logger.debug("Found %s: %s" % (filename,chksum))
                return (filename, chksum)
        return (None, None)
        
    def add_ext(self, repodata, what, ext):
        filename, chksum = self.find(what)
        logger.info("add_ext %s" % what)
        if not filename and what == 'deltainfo':
            filename, chksum = self.find('prestodelta')
        if not filename:
            return
        logger.info("found %s" % filename)
        handle = repodata.new_handle()
        repodata.set_poolstr(handle, solv.REPOSITORY_REPOMD_TYPE, what)
        repodata.set_str(handle, solv.REPOSITORY_REPOMD_LOCATION, filename)
        repodata.set_checksum(handle, solv.REPOSITORY_REPOMD_CHECKSUM, chksum)
        if ext == 'DL':
            repodata.add_idarray(handle, solv.REPOSITORY_KEYS, solv.REPOSITORY_DELTAINFO)
            repodata.add_idarray(handle, solv.REPOSITORY_KEYS, solv.REPOKEY_TYPE_FLEXARRAY)
        elif ext == 'FL':
            repodata.add_idarray(handle, solv.REPOSITORY_KEYS, solv.SOLVABLE_FILELIST)
            repodata.add_idarray(handle, solv.REPOSITORY_KEYS, solv.REPOKEY_TYPE_DIRSTRARRAY)
        repodata.add_flexarray(solv.SOLVID_META, solv.REPOSITORY_EXTERNAL, handle)

    def add_exts(self):
        repodata = self.handle.add_repodata(0)
        self.add_ext(repodata, 'deltainfo', 'DL')
        self.add_ext(repodata, 'filelists', 'FL')
        repodata.internalize()
    
    def load_ext(self, repodata):
        repomdtype = repodata.lookup_str(solv.SOLVID_META, solv.REPOSITORY_REPOMD_TYPE)
        logger.info("load_ext %s" % repomdtype)
        if repomdtype == 'filelists':
            ext = 'FL'
        elif repomdtype == 'deltainfo':
            ext = 'DL'
        else:
            return False
        sys.stdout.write("[%s:%s: " % (self.name, ext))
        sys.stdout.write("fetching]\n")
        sys.stdout.flush()
        filename = repodata.lookup_str(solv.SOLVID_META, solv.REPOSITORY_REPOMD_LOCATION)
        filechksum = repodata.lookup_checksum(solv.SOLVID_META, solv.REPOSITORY_REPOMD_CHECKSUM)
        f = self.download(filename, uncompress=True, chksum=filechksum)
        if not f:
            return False
        if ext == 'FL':
            self.handle.add_rpmmd(f, 'FL', solv.Repo.REPO_USE_LOADING|solv.Repo.REPO_EXTEND_SOLVABLES|solv.Repo.REPO_LOCALPOOL)
        elif ext == 'DL':
            self.handle.add_deltainfoxml(f, solv.Repo.REPO_USE_LOADING)
        return True

    def load_patterns(self):
        logger.debug("Loading patterns");
        (filename, filechksum) = self.find('patterns')
        if not filename:
            return False
        f = self.download(filename, uncompress=True, chksum=filechksum)
        if not f:
            return False

        # parse XML (and strip all namespaces)
        it = ET.iterparse(f)
        for _, el in it:
            if el.tag.find('}')>=0:
                el.tag = el.tag.split('}', 1)[1]
        root = it.root

        for elt in root.findall('pattern'):
            name=elt.find("name")
            if name is None:
                logger.warning("Invalid pattern name")
                continue

            name=name.text
            if name in self.patterns:
                continue

            logger.debug("Found pattern %s" % name)
            pat=pattern(name)
                
            for req in elt.findall("requires/entry"):
                pkg=req.attrib['name']
                pat.add(pkg)

            self.patterns[pat.name]=pat

        return True

class repo_unknown(repo_generic):
    def load(self, pool):
        logger.warning("unsupported repo '%s': skipped" % self.name)
        return False

def load_stub(repodata):
    repo = repodata.repo.appdata
    if repo:
        return repo.load_ext(repodata)
    return False


parser = argparse.ArgumentParser()
parser.add_argument('-A', '--arch', type=str, dest="arch", help="specify host archicture (i586, armv7l, x86_64 ...)")
parser.add_argument('-r', '--repo', action="append", type=str, dest="repos", help="specify packages repositories")
parser.add_argument('-v', '--verbose', action="store_true", help="increase verbosity")
parser.add_argument('globs',help="package names or globs",nargs="*")
options = parser.parse_args()

# read all repo configs
repos = []
if not options.repos:
    logger.error("No repository defined")
    sys.exit(1)

for repourl in options.repos:
    name = re.sub("[^a-zA-Z0-9_]","_",repourl)
    repoattr = {
        'baseurl': repourl,
        'enabled': 1,
        'priority': 99,
        'autorefresh': 1,
        'type': 'rpm-md',
        'metadata_expire': 900
    }
    repo = repo_repomd(name, 'repomd', repoattr)
    repos.append(repo)

# declare pool
pool = solv.Pool()
pool.setarch(options.arch)
pool.set_loadcallback(load_stub)

# load all repos into the pool
for repo in repos:
    if int(repo['enabled']):
        repo.load(pool)
    
addedprovides = pool.addfileprovides_queue()
if addedprovides:
    for repo in repos:
        repo.updateaddedprovides(addedprovides)

pool.createwhatprovides()

def lookup_packages(globs):
    # convert arguments into jobs
    jobs = []
    for arg in globs:
        flags = solv.Selection.SELECTION_NAME|solv.Selection.SELECTION_PROVIDES|solv.Selection.SELECTION_GLOB
        flags |= solv.Selection.SELECTION_CANON|solv.Selection.SELECTION_DOTARCH|solv.Selection.SELECTION_REL
        if len(arg) and arg[0] == '/':
            flags |= solv.Selection.SELECTION_FILELIST
        sel = pool.select(arg, flags)
        if sel.isempty():
            sel = pool.select(arg, flags | solv.Selection.SELECTION_NOCASE)
            if not sel.isempty():
                logger.info("[ignoring case for '%s']" % arg)
        if sel.isempty():
            logger.warning("no package matches '%s'" % arg)
            continue
        if sel.flags() & solv.Selection.SELECTION_FILELIST:
            logger.info( "[using file list match for '%s']" % arg)
        if sel.flags() & solv.Selection.SELECTION_PROVIDES:
            logger.info("[using capability match for '%s']" % arg)
        logger.info("Found %d package(s) matching '%s'" % ( len(sel.solvables()),arg ) )
        jobs += sel.jobs(0)

    pkgs=[]

    if not jobs:
        return []

    logger.info("Selected packages:");

    for job in jobs:
        for s in job.solvables():
            pkgs.append(s)
            logger.info("  - %s" % s)

    if options.verbose:
        logger.info("Name:        %s" % s)
        logger.info("Repo:        %s" % s.repo)
        logger.info("Summary:     %s" % s.lookup_str(solv.SOLVABLE_SUMMARY))
        logger.info("Group:       %s" % s.lookup_str(solv.SOLVABLE_GROUP))
        str = s.lookup_str(solv.SOLVABLE_URL)
        if str:
            logger.info("Url:         %s" % str)
        str = s.lookup_str(solv.SOLVABLE_LICENSE)
        if str:
            logger.info("License:     %s" % str)
        for i in s.lookup_idarray(solv.SOLVABLE_REQUIRES):
            logger.info("Requires: %s" % pool.id2str(i))

        for d in s.lookup_deparray(solv.SOLVABLE_REQUIRES):
            sel=d.Selection_provides()
            for pkg in sel.solvables():
                logger.info("Depends: %s" % pkg.name)

    return pkgs

def lookup_dependencies(pkgs,result,depth=0):
    logger.debug("lookup deps %d: %s" % (depth,[ pkg.name for pkg in pkgs ]))

    if len(result['depth']) <= depth:
        result['depth'].append(set())

    for s in pkgs:
        result['all'].add(pkg.name)
        result['depth'][depth].add(pkg.name)

        for d in s.lookup_deparray(solv.SOLVABLE_REQUIRES):
            sel=d.Selection_provides()
            for pkg in sel.solvables():
                if pkg.name not in result['all']:
                    logger.debug("found dep at depth %d: %s -> %s" % (depth,s.name,pkg.name))
                    lookup_dependencies([pkg],result,depth+1)



def main():
    patterns={};

    # consider that a pattern content is passed in command line
    if len(options.globs):
        pat=pattern("adhoc")
        for x in options.globs:
            pat.add(x)

        pat.solve()

        result={
            'all': set(),
            'depth': []
        }
        patterns[pat.name]=pat

    else:
        # eval all patterns 
        for repo in repos:
            for pat in repo.patterns.itervalues():
                pat.solve()
                patterns[pat.name]=pat

    usedpkgs=set()
    for p in patterns.itervalues():
        for x in p.depends:
            usedpkgs.add(x)

    logger.info("Used packages: %s" % len(usedpkgs))
    for x in sorted(usedpkgs):
        print x
                

main()
